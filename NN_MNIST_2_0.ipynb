{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_MNIST_2.0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNSnrxSkgcgT3YjooGSGswe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyas1209/ACM_Round2_ML/blob/main/NN_MNIST_2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OjnVInZmwx1"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_openml\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3N03yJim7Tb"
      },
      "source": [
        "#loading MNIST dataset using sklearn.datasets\n",
        "\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceGAHcq6pDnw",
        "outputId": "c6ff2da6-b337-45b6-d39a-2d4fd1cdb18d"
      },
      "source": [
        "X = np.array(X)\n",
        "\n",
        "y "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['5', '0', '4', ..., '4', '5', '6'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojY_sZ8QpE0u"
      },
      "source": [
        "\n",
        "def one_hot_encoding(Y):\n",
        "  n_col = np.max(Y) + 1\n",
        "  ohe_base = np.zeros((len(Y), n_col))\n",
        "  for i in range(len(Y)):\n",
        "      ohe_base[i, Y[i]] = 1.\n",
        "  return ohe_base\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lDVmwTJpNeM",
        "outputId": "0c90a93e-e7aa-4be5-aa16-dbc9f4fe6068"
      },
      "source": [
        "#performing one hot encoding\n",
        "for i in range(len(y)):\n",
        "\t y[i] = int(y[i])\n",
        " \n",
        "\n",
        "  \n",
        "\n",
        "y = np.array(y)\n",
        "\n",
        "\n",
        "y = one_hot_encoding(y)\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmOAJxGupPTg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95TsW-wzpPe3"
      },
      "source": [
        "#calculating the sigmoid function\n",
        "def sigmoid(X):\n",
        "    return 1/(1+np.exp(-X ))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP-oaqtZsAHH"
      },
      "source": [
        "#calculating the sigmoid gradient\n",
        "def sigmoid_gradient(X): \n",
        "    return sigmoid(X)*(1 - sigmoid(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nV7rFf4plNH"
      },
      "source": [
        "\n",
        "#Training the neural network\n",
        "def NNtrain(X,y,w1,w2,alpha,num_iter):\n",
        "\n",
        "  for i in range(num_iter):\n",
        "\n",
        "      #Feed forward\n",
        "      a1 = X_train\n",
        "      m = a1.shape[0]\n",
        "      a2 = sigmoid(np.dot(a1, w1))\n",
        "      a3 = sigmoid(np.dot(a2, w2))\n",
        "      \n",
        "\n",
        "      #Back propagation using gradient descent\n",
        "      a3_error = y - a3\n",
        "\n",
        "      Delta_a3 = (a3_error * sigmoid_gradient(a3))#+(np.sum(w2))\n",
        "      \n",
        "      a2_error = Delta_a3.dot(w2.T)\n",
        "      Delta_a2 = (a2_error * sigmoid_gradient(a2))#+(np.sum(w1))\n",
        "      \n",
        "      w2 += (a2.T.dot(Delta_a3)+((np.sum(Delta_a3))/m)) * alpha\n",
        "      w1 += (a1.T.dot(Delta_a2)+((np.sum(Delta_a2))/m))* alpha\n",
        "\n",
        "  train_deets = [w1,w2,a3_error]\n",
        "  return train_deets \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ4T10ZEplW8"
      },
      "source": [
        "def NNtest(X,y,w1,w2):\n",
        "  a1 = X\n",
        "  a2 = sigmoid(np.dot(a1, w1))\n",
        "  a3 = sigmoid(np.dot(a2, w2))\n",
        "\n",
        "  a3_error = y - a3\n",
        "\n",
        "  error = np.mean(np.abs(a3_error))\n",
        "  test_score = (1 - error) \n",
        "\n",
        "  return test_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpAH2cQwvWI1"
      },
      "source": [
        "def train_score(err):\n",
        "    error = np.mean(np.abs(err))\n",
        "    score = (1 - error) \n",
        "    return score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGb6K3Gyup48"
      },
      "source": [
        "#Splitting data to training testing ddata\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size =0.15 ,test_size=0.0375)\n",
        "    \n",
        "#random generating weights\n",
        "theta_1 = 2*np.random.random((784, 25)) - 1 #weights to be applied to get the hidden layer\n",
        "theta_2 = 2*np.random.random((25, 10)) - 1  #weights to be applied to get the output layer\n",
        "\n",
        "\n",
        "alpha = 0.1\n",
        "num_iter = 1000\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NiHkIjgj1LF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95611a42-5935-4f30-91ab-40486a8e7f36"
      },
      "source": [
        "#training the neural network\n",
        "\n",
        "training = NNtrain(X_train,y_train,theta_1,theta_2,alpha,num_iter)\n",
        "weight_1 = training[0]\n",
        "weight_2 = training[1]\n",
        "error = training[2]\n",
        "train_score = train_score(error)\n",
        "\n",
        "print(\"The training score is :\"+str(train_score))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The training score is :0.8816679397594674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1p8vMc3slaUb",
        "outputId": "34c28055-2d0b-47cb-db44-029e92966c6b"
      },
      "source": [
        "#testing the neural network\n",
        "\n",
        "test_score = NNtest(X_test,y_test,weight_1,weight_2)\n",
        "\n",
        "print(\"The test score is:\",test_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The test score is: 0.9187788592203724\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}